---
title: Mirror and render pipelines
date: 2026-01-04
tags: [unity,c#,linear algebra]
head:
  - - meta
    - name: UE5
      content: tinf
  - - meta
    - name: GameEngine
      content: tinf
---

Record UE5 Gameplay process.

---



采用stencil/Geometry方案：开销与镜子在屏幕上的大小成正比。镜子越小，性能越省，
直接写在屏幕缓冲区，没有中间商，因为是直接渲染几何体，永远是屏幕原生分辨率，无限清晰。


problem1:如果使用 Render Texture 来做镜子，分辨率设置为 1024x1024。当镜子在画面中只占 10x10 像素大小时（比如角色离镜子很远），你的 GPU 依然在全力渲染 1024x1024 的 RT，这叫什么性能浪费？应该如何优化？

ans:严重的过采样导致的过度着色和带宽浪费

传统RT方案：LOD策略，即动态分辨率，根据相机到镜面的距离，线性或分级降低RT的尺寸来降低fragment的压力和显存带宽小号，。然后基于stencil buffer的平面反射利用光栅化管线的特性，开销与镜面屏幕上的像素占比成正比还能保持绝对清晰度。



后 planar reflection，，有点灾难感觉自己先攻错方向了，
草记一下未来要做的tag等等

动作动画流程/下雨/昏暗场景/pcg高楼/氛围背景

先做这样的氛围
阴暗潮湿（体积雾/雨）
默的力场 —— 基于计算着色器的流体畸变 (Compute Shader Distortion)
Signed Distance Field (SDF) + Ray Marching 或者 Compute Shader Vector Field。

鼠标点击屏幕，产生一个斥力圈，让一张网格图片产生扭曲。

unity怜项目部分：
(数学与算法研究部分)
- [√] planar reflection&stencil buffer
- [ ] 体积云体积雾体积光（raymarching等
- [ ]写远处的海面（一堆方案，shadertoy搬运预备役
- [ ]下雨路面材质升级薄膜干涉
- [ ]怜写雨水排斥的力场
- [ ]加入风场

(美术和工具链研究)
给完善环境和打光
升级粒子雨的vfx思考更多方案等
把怜的模型发型重做贴图重绘
给怜重新做人物渲染
k简单动作

(硬件研究)
我想把我做过的所有东西一通进行性能分析和硬件分析，但我看不懂cpu和gpu的工作原理

渲染管线也可以直接对应阶段复盘与思考？
0.

1.应用阶段：CPU
- 准备基本场景数据：
(1)场景：物体数据怜/一堆场景/
物体变换数据/位置/渲染/缩放（怜的第三人称freelock camera/雨滴粒子算是数据的话就有碰到角色会分开的算法


(2)摄像机：位置/方向/远近裁剪平面
镜子那个给planar reflection渲染RT的摄像机问题数据（这个貌似确实涉及了整条管线,话说你貌似是把近裁剪面做了啥处理来着的.?

(3)光源：各种类型
设置光源
设置阴影：听到了什么优化方面深度偏移近平面偏移不知道能不能用
逐光源绘制贴图（sdf画面部阴影？，体积云算什么...？）


- 加速算法粗粒度剔除：等等但这里就要有粗粒度剔除那我的镜子怎么办？？）
可见场景物体裁剪（之前又是planar reflection的鬼畜现象）
八叉树
bsp树
K-D树
BVH

- 设置渲染状态准备渲染参数：
(1)绘制设置：使用着色器/合批方式（没听过的术语）
(2)绘制物体的顺序：
相对摄像机距离
材质renderQueue
UICanvas
（渲染ui场景模式不一样？（那我看sdf又能做那种ui又能做我的雨丝又能做卡渲面部？
由远到近/先渲染不透明再渲染半透明（？区别何？等等，那你和逐片元操作最终的混合是。？就是在这一步决定逐片元操作的混合该如何混合(cpu)然后让gpu去着色是吗？我写的hlsl/glsl?
三脚猫目前方案：全shader
但是有个项目貌似和UICanvas那个渲染有关）
(3)渲染目标：
FrameBuffer
RenderTexture
（什么是渲染到frame buffer还是啥,什么是渲染操作输出的对象是输出到真缓存里（frame buffer还是到renderTexture里？？
我想起之前弄planar relection然后一堆重影画面现象）/

(4)渲染模式
前向渲染
延迟渲染（这两到底是啥玩意啊...）
（unity等等完全不懂,我记得之前planarreflection又在报urp/sro错

 - 调用draw call输出渲染图元到显存Gpu处理去(所以说上面过程基本都在cpu完成了？buffer指的就是cpu上的dram还是gpu？不得不说buffer这个词真神秘...)

![](/image9.webp)



2.几何阶段：
- 顶点着色(Vertex Shading)：
就是shader？配到gpu不同工作单元去处理？人物渲染/海面/潮湿路面/薄膜干涉？
貌似不是，是坐标系变换，就是从模型坐标系通过那PRS矩阵换过去（经典PositionRotationScale，用PRS代称下transformation
然后最终渲染是我们视角内的东西也就换成观察坐标系（我怎么感觉自己在games101的笔记里面做过这块，

（以下是之前看games101搬运过来的md:）
```md
模型坐标 → 世界坐标 → 观察坐标 → 裁剪坐标 → NDC坐标 → 屏幕坐标
     ↓         ↓         ↓         ↓         ↓         ↓
   几何数据   场景布局   相机相对   齐次坐标   标准化    像素位置
                             透视投影开始   透视投影结束
                                         ↑
                                 透视校正插值发生在这里(但是由w_clip存储z_view的值)


```

不是我怎么感觉还是有点问题。。
然后百人计划后面说视图坐标系完了就是投影坐标系(3D-2D)
就是MVP

然后还有计算顶点光照(雾)

- (可选)顶点着色器输出顶点交给曲面细分(blender里面那个什么sub东西？我记得是多加一些面还是..？)和几何着色器处理(这啥)
这俩对gpu有要求
但是涉及人物貌似是需要高模降低模的逆向过程
图元着色器貌似也在blender里面接触过...
- 投影(Projection) 经典MVP 这里不搬笔记了
- 裁剪(Clipping) CVV/curling(可配置)这个貌似就是怜看见小时候自己设置layer然后不同摄像机 curling的layer不一样看到就不一样了
（unity/opengl:xyz:-1~1/ue：d3d xy：-1~1，z：0~1）
然后屏映射平面坐标系 
（不过这样来看是不是UI的话就没有3d模型空间也就是不涉及投影和透视修正了（那完了。.我感觉我的小组那个通讯录结课大作业接了个vulkan就为了生成一个imgui-vulkan窗口会被老师干死。：）。。。。。实在不行我就去加点3d东西，但问题是：vulkan。（笑嘻，《论我是怎么把自己逼到进退两难的地步的》）
。完蛋
顶点是否在视锥体内不在就剔除，貌似就和上面应用阶段那个算法有点像吧...？
- 屏幕映射(Screen Mapping):连续到离散成为像素点了？（坐标系差异 opengl/D3D等



（然后得到每个顶点在屏幕空间的位置之后）
3.光栅化阶段:
(我怎么总是感觉会把这个阶段和绘制模型UV那个阶段搞混淆..)我只能抽象一点理解光栅化是将怜等模型三角形顶点已经成为屏幕坐标后在那个平面上进行采样绘制了？（大概
- 三角形设置：顶点->计算边界。（这里只讨论三角形了，所以曲线啥..?blender里面有一堆path curve brezier之类的）

- 三角形遍历:什么顶点和1像素之间的区分（所以那些采样是在这里划分哦？）
这里就是比较有名SSAA(直接渲染放大n倍分辨率的buffer(不是，buffer到底是什么。。中文是缓存还是测试还是啥...))/MSAA(多个采样算，覆盖测试 遮挡测试(。。。这些测试是具体的算法吗看之前在1阶段那个算法也有过)。立刻可与4上色进行联动)
覆盖：子采样点是否在三角形内/遮挡测试：和zbuffer比较，都通过，是三角形。
(都是test但注意概念区分...(指4中))
综上得到三角形覆盖信息(片元序列这样)


4.逐片元操作：
- 片元着色(Fragment Shader):哦原来games101那个三角形插值是用在这里的...所以实际的“像素位置”以及UV颜色等还是要经过这里的插值
alphaTest(rgba中a)/Depth Buffer Test/stencil Test(那我之前有个镜子实现方案(仅仅针对一个几何体网格体想的是glsl中的stencil buffer那里，就是测试镜子(貌似镜子作为模版stencil然后剔除对面的像, 当时和现在其实一直有些晕乎尝试用3d蒙版理解...)))
讲真作为z-buffer作比较的话...我就当作z-buffer是某种已经存好深度的“图片数组”来看吧...
但你具体怎么比较呢？地表片元它难道用map储存键和值吗？（一个片元着色数据完对应一个深度值）？。不对那还有UV之类的东西我觉得应该是结构体吧...结构体...貌似也不是（貌似还有其他数据结构能存啊... 算了回头去查查源码问问看。
。好像逻辑打结了，这种用来存储的数据结构就是“buffer”。吧。好吧逻辑貌似通了。
然后这里就可以去仔细处理那个该死镜面planar reflection等我马上去研究...（？但是流程服务这一块又不考虑了？
可以在这里颠倒物理序列（貌似有些很炫酷的点子和效果在我脑子里转，比如跟着一个人影走过去月远离它反而离我更近这样，就是地狱列车里面那种白伞人，但实际上只改变它的物理参数或者键值映射前进后退也很简单解决不用上升到改管线一说哦....）

。模版测试说完我怎么还没弄懂。怎么就和stencil buffer杠上了。。。

[那些Test的顺序等具体](https://chenanbao.github.io/2019/01/19/%E6%B8%B2%E6%9F%93%E7%AE%A1%E7%BA%BF/)

- 颜色混合(Color Blending):记住之前利用oblique queue材质来区分...是和1中那个渲染设置有关？我写的shader？

- 目标缓冲区：。frame buffer（帧缓冲区，所以这个就是真·屏幕空间是吗？）
或者RT，贴图好理解。





5.后处理:
纯滤镜的后处理，这方面具体效果再具体拆分和分析（。目前只知道一些零散的个例，貌似还没办法很系统系统地划分。即可。


ue5江南项目部分：
tmd我tm都还没起步都


最近要干的事情：
但是我要准备三天后的高数考试
我要搞完四天后上交的程序设计结课大作业把imgui的bug修完以及搬运latex史山报告(
我莫名刷到个imgui-vue.brige的天才项目于是想搬运代码升级ui交互界面，应该是没时间升级了
同时考虑到数据内存占用问题我想升级数据库处理
我还想在unity里面绘制风格化前端以适应我结课项目的.dll，但是应该没时间做了。)

但我还要去做别人的生日礼物(unity2d,之前做生日礼物项目自己卷自己导致要死。
我想去弄懂我搬过来的hlsl分形为什么鬼畜以及如何和生日礼物适配)

但我还要去研究blender的pcg程序化生成和ue5的bim数字孪生渲染展示，rvt模型那块应付一些东西



